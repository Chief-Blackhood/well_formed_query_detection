{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Chief-Blackhood/cautious-invention/blob/main/IRE_Assignment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3CJMqcwMF1lq"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mm_PqsFNlc_C",
    "outputId": "20e9ef0b-79e0-415c-aa1f-ba10f765524d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Nov 15 05:54:40 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omkPtwJXGV_I"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFFZRf3xG77B"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-JjXSf_LwNFI",
    "outputId": "e7327035-6842-4875-cd09-1a86359f5746"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xSlLw5bPIvCk"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.tsv\", sep='\\t', names=[\"text\", \"label\"])\n",
    "dev = pd.read_csv(\"dev.tsv\", sep='\\t', names=[\"text\", \"label\"])\n",
    "test = pd.read_csv(\"test.tsv\", sep='\\t', names=[\"text\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D8divxCWJMNw"
   },
   "outputs": [],
   "source": [
    "def change_label(df):\n",
    "  df.loc[df['label'] >= 0.8, 'label'] = 1\n",
    "  df.loc[df['label'] < 0.8, 'label'] = 0\n",
    "  df['label'] = df['label'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F9JLBYgqJV3T"
   },
   "outputs": [],
   "source": [
    "for df in [train, dev, test]:\n",
    "  change_label(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJ0I9tzxKk89"
   },
   "outputs": [],
   "source": [
    "def class_distribution(df):\n",
    "  print(df['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UXtLdnHMBsY",
    "outputId": "f153e620-0f8c-4f9e-e09b-aec33a91a155"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.611486\n",
      "1    0.388514\n",
      "Name: label, dtype: float64\n",
      "0    0.611467\n",
      "1    0.388533\n",
      "Name: label, dtype: float64\n",
      "0    0.615584\n",
      "1    0.384416\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for df in [train, dev, test]:\n",
    "  class_distribution(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M7NkA3BoMa5t"
   },
   "source": [
    "### Import BERT Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hcOh67nxMiq9",
    "outputId": "891e57d1-c7aa-4f2d-bb24-b4a3537661a8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert = AutoModel.from_pretrained('bert-base-uncased', return_dict=False)\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKwosG4JNxuI"
   },
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6r-Ihr_dM-7f"
   },
   "source": [
    "#### Histogram to find length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "e2ui9Yf2MvjC",
    "outputId": "1e2397ea-830e-488e-fc70-5c6406b7f08c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc85980f9d0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_len = [len(tokenizer.tokenize(t)) for t in train['text']]\n",
    "pd.Series(text_len).hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bXS424GUM4VD"
   },
   "outputs": [],
   "source": [
    "# since 25 length text covers most of the sentences\n",
    "max_seq_len = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1Y1OiExN2II"
   },
   "source": [
    "#### Tokenize and Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBbckS2vNqUr"
   },
   "outputs": [],
   "source": [
    "def tok_enc_seq(text):\n",
    "  return tokenizer.batch_encode_plus(text.tolist(), max_length=max_seq_len, padding='max_length', truncation=True, return_token_type_ids=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqqN80paOYb2"
   },
   "outputs": [],
   "source": [
    "tokens_train = tok_enc_seq(train['text'])\n",
    "tokens_dev = tok_enc_seq(dev['text'])\n",
    "tokens_test = tok_enc_seq(test['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2ybSRURPjE7"
   },
   "source": [
    "### Interger Sequences -> Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kt1pcq6rPdjZ"
   },
   "outputs": [],
   "source": [
    "def int_to_tensor(tokens, df):\n",
    "  seq = torch.tensor(tokens['input_ids'])\n",
    "  mask = torch.tensor(tokens['attention_mask'])\n",
    "  y = torch.tensor(df['label'].tolist())\n",
    "  return seq, mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YuKdskv_QWz1"
   },
   "outputs": [],
   "source": [
    "train_seq, train_mask, train_y = int_to_tensor(tokens_train, train)\n",
    "dev_seq, dev_mask, dev_y = int_to_tensor(tokens_dev, dev)\n",
    "test_seq, test_mask, test_y = int_to_tensor(tokens_test, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UBzih6_vtmWl"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HG8yi71NQ7JE"
   },
   "source": [
    "### Create DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wvr6Dj1HQrTo"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJwPwHVZRXWn"
   },
   "outputs": [],
   "source": [
    "def create_dataloader(seq, mask, y):\n",
    "  data = TensorDataset(seq, mask, y)\n",
    "  sampler = RandomSampler(data)\n",
    "  dataloader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n",
    "  return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1LWKlJuwK1a"
   },
   "outputs": [],
   "source": [
    "train_dataloader = create_dataloader(train_seq, train_mask, train_y)\n",
    "dev_dataloader = create_dataloader(dev_seq, dev_mask, dev_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECSQTkggxVyh"
   },
   "source": [
    "### Freeze BERT model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rPEeLMf3wlNq"
   },
   "outputs": [],
   "source": [
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rGiPkLeuyizE"
   },
   "source": [
    "### Define BERT Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xzHk-lU1yh27"
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "  def __init__(self, bert):\n",
    "    super(BERT_Arch, self).__init__()\n",
    "    self.bert = bert\n",
    "    self.dropout = nn.Dropout(0.1)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc1 = nn.Linear(768, 512)\n",
    "    self.fc2 = nn.Linear(512, 2)\n",
    "    # self.softmax = nn.LogSoftmax(dim=1)\n",
    "  \n",
    "  def forward(self, send_id, mask):\n",
    "    _, cls_hs = self.bert(send_id, attention_mask=mask)\n",
    "    x = self.fc1(cls_hs)\n",
    "    x = self.relu(x)\n",
    "    x = self.dropout(x)\n",
    "    x = self.fc2(x)\n",
    "    # x = self.softmax(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kKBxC2Td0X8x"
   },
   "outputs": [],
   "source": [
    "model = BERT_Arch(bert)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "93eXJuWL1RsH"
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "optimizer = AdamW(model.parameters(), lr = 0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GnwFKzn1hcd"
   },
   "source": [
    "### Find class weights to remove class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3AabrBgq1RzG"
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# class_wts = compute_class_weight('balanced', np.unique(train['label']), train['label'])\n",
    "\n",
    "# print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0zeNue6k1aBc"
   },
   "outputs": [],
   "source": [
    "# weights = torch.tensor(class_wts, dtype=torch.float)\n",
    "# weights = weights.to(device)\n",
    "\n",
    "# cross_entropy\n",
    "cross_entropy = nn.CrossEntropyLoss()\n",
    "# cross_entropy = nn.NLLLoss()\n",
    "\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAnObfc43Ru0"
   },
   "source": [
    "### Fine-Tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UjfQGeBO1aDf"
   },
   "outputs": [],
   "source": [
    "def train():\n",
    "  model.train()\n",
    "  total_loss  = 0\n",
    "  \n",
    "  # empty list to save model predictions\n",
    "  total_preds=[]\n",
    "  \n",
    "  for step, batch in enumerate(train_dataloader):\n",
    "    \n",
    "    # progress update after every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      print(f'  Batch {step}  of  {len(train_dataloader)}.')\n",
    "\n",
    "    batch = [r.to(device) for r in batch]\n",
    "    sent_id, mask, labels = batch\n",
    "    # print(sent_id)\n",
    "\n",
    "    # clear previously calculated gradients \n",
    "    model.zero_grad()        \n",
    "\n",
    "    # get model predictions for the current batch\n",
    "    preds = model(sent_id, mask)\n",
    "    # print(type(preds), type(labels))\n",
    "\n",
    "    loss = cross_entropy(preds, labels)\n",
    "    print(loss)\n",
    "    total_loss = total_loss + loss.item()\n",
    "    loss.backward()\n",
    "\n",
    "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    preds=preds.detach().cpu().numpy()\n",
    "\n",
    "    total_preds.append(preds)\n",
    "\n",
    "  avg_loss = total_loss / len(train_dataloader)\n",
    "  \n",
    "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "  # reshape the predictions in form of (number of samples, no. of classes)\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  #returns the loss and predictions\n",
    "  return avg_loss, total_preds\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USiIKuHwhTcD"
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "  \n",
    "  print(\"\\nEvaluating...\")\n",
    "  \n",
    "  model.eval()\n",
    "\n",
    "  total_loss = 0\n",
    "  \n",
    "  total_preds = []\n",
    "\n",
    "  # iterate over batches\n",
    "  for step,batch in enumerate(dev_dataloader):\n",
    "    \n",
    "    # Progress update every 50 batches.\n",
    "    if step % 50 == 0 and not step == 0:\n",
    "      \n",
    "      # Calculate elapsed time in minutes.\n",
    "      # elapsed = format_time(time.time() - t0)\n",
    "      print(f'  Batch {step}  of  {len(dev_dataloader)}.')\n",
    "\n",
    "    batch = [t.to(device) for t in batch]\n",
    "\n",
    "    sent_id, mask, labels = batch\n",
    "    # print(sent_id)\n",
    "\n",
    "    # deactivate autograd\n",
    "    with torch.no_grad():\n",
    "      \n",
    "      preds = model(sent_id, mask)\n",
    "\n",
    "      loss = cross_entropy(preds,labels)\n",
    "\n",
    "      total_loss = total_loss + loss.item()\n",
    "      preds = preds.detach().cpu().numpy()\n",
    "\n",
    "      total_preds.append(preds)\n",
    "\n",
    "  avg_loss = total_loss / len(dev_dataloader) \n",
    "\n",
    "\n",
    "  total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "  return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5lzj1WWh203"
   },
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pQy30u0Ah1Ra",
    "outputId": "6b5f0ed5-9189-4f9a-f079-af7a40a59738"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 3\n",
      "  Batch 50  of  547.\n",
      "  Batch 100  of  547.\n",
      "  Batch 150  of  547.\n",
      "  Batch 200  of  547.\n",
      "  Batch 250  of  547.\n",
      "  Batch 300  of  547.\n",
      "  Batch 350  of  547.\n",
      "  Batch 400  of  547.\n",
      "  Batch 450  of  547.\n",
      "  Batch 500  of  547.\n",
      "\n",
      "Evaluating...\n",
      "  Batch 50  of  118.\n",
      "  Batch 100  of  118.\n",
      "\n",
      "Training Loss: 0.616\n",
      "Validation Loss: 0.568\n",
      "\n",
      " Epoch 2 / 3\n",
      "  Batch 50  of  547.\n",
      "  Batch 100  of  547.\n",
      "  Batch 150  of  547.\n",
      "  Batch 200  of  547.\n",
      "  Batch 250  of  547.\n",
      "  Batch 300  of  547.\n",
      "  Batch 350  of  547.\n",
      "  Batch 400  of  547.\n",
      "  Batch 450  of  547.\n",
      "  Batch 500  of  547.\n",
      "\n",
      "Evaluating...\n",
      "  Batch 50  of  118.\n",
      "  Batch 100  of  118.\n",
      "\n",
      "Training Loss: 0.564\n",
      "Validation Loss: 0.591\n",
      "\n",
      " Epoch 3 / 3\n",
      "  Batch 50  of  547.\n",
      "  Batch 100  of  547.\n",
      "  Batch 150  of  547.\n",
      "  Batch 200  of  547.\n",
      "  Batch 250  of  547.\n",
      "  Batch 300  of  547.\n",
      "  Batch 350  of  547.\n",
      "  Batch 400  of  547.\n",
      "  Batch 450  of  547.\n",
      "  Batch 500  of  547.\n",
      "\n",
      "Evaluating...\n",
      "  Batch 50  of  118.\n",
      "  Batch 100  of  118.\n",
      "\n",
      "Training Loss: 0.553\n",
      "Validation Loss: 0.506\n"
     ]
    }
   ],
   "source": [
    "best_valid_loss = float('inf')\n",
    "\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print(f'\\n Epoch {epoch + 1} / {epochs}')\n",
    "    \n",
    "    train_loss, _ = train()\n",
    "    \n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
    "    \n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mNZYonLmiMU6"
   },
   "source": [
    "### Load saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c3vi8MPY1aF2",
    "outputId": "d6b2168c-1f2e-4c61-ead9-1436a85c8530"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load weights of best model\n",
    "path = 'saved_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXyGvBPliRNZ"
   },
   "source": [
    "### Get test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TYBGoWKziPWH"
   },
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "  preds = model(test_seq.to(device), test_mask.to(device))\n",
    "  preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O0soErCjicsj",
    "outputId": "69e297fb-b54e-4d1a-e1b2-a6e132d79b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.78      0.79      2370\n",
      "           1       0.66      0.69      0.68      1480\n",
      "\n",
      "    accuracy                           0.75      3850\n",
      "   macro avg       0.73      0.73      0.73      3850\n",
      "weighted avg       0.75      0.75      0.75      3850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# model's performance\n",
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "LDNrYfjYifYu",
    "outputId": "62ad7e01-52c3-4c52-a25f-b09cd425c8b6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1851</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>461</td>\n",
       "      <td>1019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     0     1\n",
       "row_0            \n",
       "0      1851   519\n",
       "1       461  1019"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(test_y, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pp5Wu8UqBfxr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "IRE Assignment 3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
